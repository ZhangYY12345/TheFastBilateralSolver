
@inproceedings{barron_fast_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Fast} {Bilateral} {Solver}},
	isbn = {978-3-319-46487-9},
	abstract = {We present the bilateral solver, a novel algorithm for edge-aware smoothing that combines the flexibility and speed of simple filtering approaches with the accuracy of domain-specific optimization algorithms. Our technique is capable of matching or improving upon state-of-the-art results on several different computer vision tasks (stereo, depth superresolution, colorization, and semantic segmentation) while being 10–1000××{\textbackslash}times faster than baseline techniques with comparable accuracy, and producing lower-error output than techniques with comparable runtimes. The bilateral solver is fast, robust, straightforward to generalize to new domains, and simple to integrate into deep learning pipelines.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Barron, Jonathan T. and Poole, Ben},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	keywords = {Computer Vision Task, Forward Pass, Initialization Technique, Input Target, Stereo Algorithm},
	pages = {617--632},
	file = {arXiv\:1511.03296 PDF:/Users/guillaume/Documents/Scolaire/Zotero/storage/FBNR3JL9/Barron and Poole - 2015 - The Fast Bilateral Solver.pdf:application/pdf}
}

@article{adams_fast_2010,
	title = {Fast {High}-{Dimensional} {Filtering} {Using} the {Permutohedral} {Lattice}},
	volume = {29},
	copyright = {© 2010 The Author(s) Journal compilation © 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01645.x},
	doi = {10.1111/j.1467-8659.2009.01645.x},
	abstract = {Many useful algorithms for processing images and geometry fall under the general framework of high-dimensional Gaussian filtering. This family of algorithms includes bilateral filtering and non-local means. We propose a new way to perform such filters using the permutohedral lattice, which tessellates high-dimensional space with uniform simplices. Our algorithm is the first implementation of a high-dimensional Gaussian filter that is both linear in input size and polynomial in dimensionality. Furthermore it is parameter-free, apart from the filter size, and achieves a consistently high accuracy relative to ground truth ({\textgreater} 45 dB). We use this to demonstrate a number of interactive-rate applications of filters in as high as eight dimensions.},
	language = {en},
	number = {2},
	urldate = {2018-11-08},
	journal = {Computer Graphics Forum},
	author = {Adams, Andrew and Baek, Jongmin and Davis, Myers Abraham},
	month = may,
	year = {2010},
	keywords = {and, Computer, Enhancement—Filtering, I.4.3, Image, Processing, Vision:},
	pages = {753--762},
	file = {Full Text PDF:/Users/guillaume/Documents/Scolaire/Zotero/storage/XNBGVERE/Adams et al. - 2010 - Fast High-Dimensional Filtering Using the Permutoh.pdf:application/pdf;Snapshot:/Users/guillaume/Documents/Scolaire/Zotero/storage/4NCGDKS8/j.1467-8659.2009.01645.html:text/html}
}

@inproceedings{chen_real-time_2007,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '07},
	title = {Real-time {Edge}-aware {Image} {Processing} with the {Bilateral} {Grid}},
	url = {http://doi.acm.org/10.1145/1275808.1276506},
	doi = {10.1145/1275808.1276506},
	abstract = {We present a new data structure---the bilateral grid, that enables fast edge-aware image processing. By working in the bilateral grid, algorithms such as bilateral filtering, edge-aware painting, and local histogram equalization become simple manipulations that are both local and independent. We parallelize our algorithms on modern GPUs to achieve real-time frame rates on high-definition video. We demonstrate our method on a variety of applications such as image editing, transfer of photographic look, and contrast enhancement of medical images.},
	urldate = {2018-11-08},
	booktitle = {{ACM} {SIGGRAPH} 2007 {Papers}},
	publisher = {ACM},
	author = {Chen, Jiawen and Paris, Sylvain and Durand, Frédo},
	year = {2007},
	keywords = {bilateral filter, computational photography, edge-aware image processing, real-time video processing},
	file = {ACM Full Text PDF:/Users/guillaume/Documents/Scolaire/Zotero/storage/3MCUY4GS/Chen et al. - 2007 - Real-time Edge-aware Image Processing with the Bil.pdf:application/pdf}
}

@inproceedings{tomasi_bilateral_1998,
	address = {Bombay, India},
	title = {Bilateral filtering for gray and color images},
	isbn = {978-81-7319-221-0},
	url = {http://ieeexplore.ieee.org/document/710815/},
	doi = {10.1109/ICCV.1998.710815},
	abstract = {Bilateral ﬁltering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with ﬁlters that operate on the three bands of a color image separately, a bilateral ﬁlter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard ﬁltering, bilateral ﬁltering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.},
	language = {en},
	urldate = {2018-11-13},
	booktitle = {Sixth {International} {Conference} on {Computer} {Vision} ({IEEE} {Cat}. {No}.98CH36271)},
	publisher = {Narosa Publishing House},
	author = {Tomasi, C. and Manduchi, R.},
	year = {1998},
	pages = {839--846},
	file = {Tomasi and Manduchi - 1998 - Bilateral filtering for gray and color images.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/EKTMVY5H/Tomasi and Manduchi - 1998 - Bilateral filtering for gray and color images.pdf:application/pdf}
}

@book{adams_high-dimensional_2011,
	title = {High-dimensional {Gaussian} {Filtering} for {Computational} {Photography}},
	abstract = {Over the last decade, digital imaging has become ubiquitous. The advent of cheap digital cameras, and the inclusion of cameras in almost all mobile devices, has made photography one of the basic ways in which people record and communicate experiences. The ubiquity of cameras has imposed new constraints on their physical form. Camera modules are expected to be thin, light, and cheap. These restrictions make the production of high-quality images challenging. We turn to increasingly sophisticated algorithmic tools to transform the raw data captured by a camera into a photograph. This dissertation focuses on one such family of algorithmic tools: those expressible as a Gauss transform. One popular technique in this family is the bilateral filter, which smooths the fine detail in an image without crossing strong edges. It can be used to isolate and control the sharpness, tone, and contrast of a photograph at various scales. Its relatives, the joint-bilateral filter and the joint-bilateral upsample, allow for the fusion of data from multiple images. Another popular technique in the same family is non-local means, which denoises an image by replacing each pixel with the average color of all other pixels in the image with a similar local neighborhood. A naive implementation of these algorithms is prohibitively slow. This dissertation unifies these algorithms under a common framework, describes a variety of applications of the transform in photographic image processing, and presents two new data structures to accelerate the computation of such transforms: the permutohedral lattice, and the Gaussian kd-tree.},
	language = {en},
	publisher = {Stanford University},
	author = {Adams, Andrew Bensley},
	year = {2011},
	note = {Google-Books-ID: ihe0nfm97eIC}
}

@article{paris_fast_nodate,
	title = {A {Fast} {Approximation} of the {Bilateral} {Filter} using a {Signal} {Processing} {Approach}},
	abstract = {The bilateral ﬁlter is a nonlinear ﬁlter that smoothes a signal while preserving strong edges. It has demonstrated great eﬀectiveness for a variety of problems in computer vision and computer graphics, and a fast version has been proposed. Unfortunately, little is known about the accuracy of such acceleration. In this paper, we propose a new signalprocessing analysis of the bilateral ﬁlter, which complements the recent studies that analyzed it as a PDE or as a robust statistics estimator. Importantly, this signal-processing perspective allows us to develop a novel bilateral ﬁltering acceleration using a downsampling in space and intensity. This aﬀords a principled expression of the accuracy in terms of bandwidth and sampling. The key to our analysis is to express the ﬁlter in a higher-dimensional space where the signal intensity is added to the original domain dimensions. The bilateral ﬁlter can then be expressed as simple linear convolutions in this augmented space followed by two simple nonlinearities. This allows us to derive simple criteria for downsampling the key operations and to achieve important acceleration of the bilateral ﬁlter. We show that, for the same running time, our method is signiﬁcantly more accurate than previous acceleration techniques.},
	language = {en},
	author = {Paris, Sylvain and Durand, Fredo},
	pages = {12},
	file = {Paris and Durand - A Fast Approximation of the Bilateral Filter using.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/3SK244AC/Paris and Durand - A Fast Approximation of the Bilateral Filter using.pdf:application/pdf}
}

@inproceedings{barron_fast_2015,
	address = {Boston, MA, USA},
	title = {Fast bilateral-space stereo for synthetic defocus},
	isbn = {978-1-4673-6964-0},
	url = {http://ieeexplore.ieee.org/document/7299076/},
	doi = {10.1109/CVPR.2015.7299076},
	abstract = {Given a stereo pair it is possible to recover a depth map and use that depth to render a synthetically defocused image. Though stereo algorithms are well-studied, rarely are those algorithms considered solely in the context of producing these defocused renderings. In this paper we present a technique for efﬁciently producing disparity maps using a novel optimization framework in which inference is performed in “bilateral-space”. Our approach produces higher-quality “defocus” results than other stereo algorithms while also being 10 − 100× faster than comparable techniques.},
	language = {en},
	urldate = {2018-11-20},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Barron, Jonathan T. and Adams, Andrew and Shih, YiChang and Hernandez, Carlos},
	month = jun,
	year = {2015},
	pages = {4466--4474},
	file = {Barron et al. - 2015 - Fast bilateral-space stereo for synthetic defocus.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/LAY3WMAQ/Barron et al. - 2015 - Fast bilateral-space stereo for synthetic defocus.pdf:application/pdf}
}

@techreport{shewchuk_introduction_1994,
	address = {Pittsburgh, PA, USA},
	title = {An {Introduction} to the {Conjugate} {Gradient} {Method} {Without} the {Agonizing} {Pain}},
	institution = {Carnegie Mellon University},
	author = {Shewchuk, Jonathan R},
	year = {1994},
	file = {painless-conjugate-gradient.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/ZXN72EAI/painless-conjugate-gradient.pdf:application/pdf}
}

@inproceedings{levin_colorization_2004,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '04},
	title = {Colorization {Using} {Optimization}},
	url = {http://doi.acm.org/10.1145/1186562.1015780},
	doi = {10.1145/1186562.1015780},
	abstract = {Colorization is a computer-assisted process of adding color to a monochrome image or movie. The process typically involves segmenting images into regions and tracking these regions across image sequences. Neither of these tasks can be performed reliably in practice; consequently, colorization requires considerable user intervention and remains a tedious, time-consuming, and expensive task.In this paper we present a simple colorization method that requires neither precise image segmentation, nor accurate region tracking. Our method is based on a simple premise; neighboring pixels in space-time that have similar intensities should have similar colors. We formalize this premise using a quadratic cost function and obtain an optimization problem that can be solved efficiently using standard techniques. In our approach an artist only needs to annotate the image with a few color scribbles, and the indicated colors are automatically propagated in both space and time to produce a fully colorized image or sequence. We demonstrate that high quality colorizations of stills and movie clips may be obtained from a relatively modest amount of user input.},
	urldate = {2018-11-20},
	booktitle = {{ACM} {SIGGRAPH} 2004 {Papers}},
	publisher = {ACM},
	author = {Levin, Anat and Lischinski, Dani and Weiss, Yair},
	year = {2004},
	keywords = {colorization, recoloring, segmentation},
	pages = {689--694},
	file = {Levin et al. - Colorization using Optimization.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/4KF67HYN/Levin et al. - Colorization using Optimization.pdf:application/pdf;Submitted Version:/Users/guillaume/Documents/Scolaire/Zotero/storage/M67ANYZQ/Levin et al. - 2004 - Colorization Using Optimization.pdf:application/pdf}
}

@inproceedings{gastal_domain_2011,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '11},
	title = {Domain {Transform} for {Edge}-aware {Image} and {Video} {Processing}},
	isbn = {978-1-4503-0943-1},
	url = {http://doi.acm.org/10.1145/1964921.1964964},
	doi = {10.1145/1964921.1964964},
	abstract = {We present a new approach for performing high-quality edge-preserving filtering of images and videos in real time. Our solution is based on a transform that defines an isometry between curves on the 2D image manifold in 5D and the real line. This transform preserves the geodesic distance between points on these curves, adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrate three realizations of 1D edge-preserving filters, show how to produce high-quality 2D edge-preserving filters by iterating 1D-filtering operations, and empirically analyze the convergence of this process. Our approach has several desirable features: the use of 1D operations leads to considerable speedups over existing techniques and potential memory savings; its computational cost is not affected by the choice of the filter parameters; and it is the first edge-preserving filter to work on color images at arbitrary scales in real time, without resorting to subsampling or quantization. We demonstrate the versatility of our domain transform and edge-preserving filters on several real-time image and video processing tasks including edge-preserving filtering, depth-of-field effects, stylization, recoloring, colorization, detail enhancement, and tone mapping.},
	urldate = {2018-11-20},
	booktitle = {{ACM} {SIGGRAPH} 2011 {Papers}},
	publisher = {ACM},
	author = {Gastal, Eduardo S. L. and Oliveira, Manuel M.},
	year = {2011},
	keywords = {bilateral filter, anisotropic diffusion, domain transform, edge-preserving filtering},
	pages = {69:1--69:12},
	file = {Gastal and Oliveira - Domain Transform for Edge-Aware Image and Video Pr.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/JDM7XNM2/Gastal and Oliveira - Domain Transform for Edge-Aware Image and Video Pr.pdf:application/pdf}
}

@article{milanfar_symmetrizing_2013,
	title = {Symmetrizing {Smoothing} {Filters}},
	volume = {6},
	issn = {1936-4954},
	url = {http://epubs.siam.org/doi/10.1137/120875843},
	doi = {10.1137/120875843},
	abstract = {We study a general class of nonlinear and shift-varying smoothing ﬁlters that operate based on averaging. This important class of ﬁlters includes many well-known examples such as the bilateral ﬁlter, nonlocal means, general adaptive moving average ﬁlters, and more. (Many linear ﬁlters such as linear minimum mean-squared error smoothing ﬁlters, Savitzky–Golay ﬁlters, smoothing splines, and wavelet smoothers can be considered special cases.) They are frequently used in both signal and image processing as they are elegant, computationally simple, and high performing. The operators that implement such ﬁlters, however, are not symmetric in general. The main contribution of this paper is to provide a provably stable method for symmetrizing the smoothing operators. Speciﬁcally, we propose a novel approximation of smoothing operators by symmetric doubly stochastic matrices and show that this approximation is stable and accurate, even more so in higher dimensions. We demonstrate that there are several important advantages to this symmetrization, particularly in image processing/ﬁltering applications such as denoising. In particular, (1) doubly stochastic ﬁlters generally lead to improved performance over the baseline smoothing procedure; (2) when the ﬁlters are applied iteratively, the symmetric ones can be guaranteed to lead to stable algorithms; and (3) symmetric smoothers allow an orthonormal eigendecomposition which enables us to peer into the complex behavior of such nonlinear and shift-varying ﬁlters in a locally adapted basis using principal components. Finally, a doubly stochastic ﬁlter has a simple and intuitive interpretation. Namely, it implies the very natural property that every pixel in the given input image has the same sum total contribution to the output image.},
	language = {en},
	number = {1},
	urldate = {2018-11-22},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Milanfar, Peyman},
	month = jan,
	year = {2013},
	pages = {263--284},
	file = {Milanfar - 2013 - Symmetrizing Smoothing Filters.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/FP63ECJ9/Milanfar - 2013 - Symmetrizing Smoothing Filters.pdf:application/pdf}
}

@article{ruiz_symmetry_nodate,
	title = {A {Symmetry} {Preserving} {Algorithm} for {Matrix} {Scaling}},
	abstract = {We present an iterative algorithm which asymptotically scales the inﬁnity-norm of each row and each column of a matrix to one. This scaling algorithm preserves symmetry of the original matrix and shows fast linear convergence with an asymptotic rate of 1/2. We discuss extensions of the algorithm to the one-norm, and by inference to other norms. For the one-norm case, we establish convergence results that are enjoyed by some other scaling algorithms. We demonstrate experimentally that the scaling algorithm improves the conditioning of the matrix and that it helps direct solvers by reducing the need for pivoting.},
	language = {en},
	author = {Ruiz, Daniel and Uçar, Bora},
	pages = {25},
	file = {Ruiz and Uçar - A Symmetry Preserving Algorithm for Matrix Scaling.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/TDMG7Q6N/Ruiz and Uçar - A Symmetry Preserving Algorithm for Matrix Scaling.pdf:application/pdf}
}

@inproceedings{park_high_2011,
	address = {Barcelona, Spain},
	title = {High quality depth map upsampling for 3D-{TOF} cameras},
	isbn = {978-1-4577-1102-2 978-1-4577-1101-5 978-1-4577-1100-8},
	url = {http://ieeexplore.ieee.org/document/6126423/},
	doi = {10.1109/ICCV.2011.6126423},
	abstract = {This paper describes an application framework to perform high quality upsampling on depth maps captured from a low-resolution and noisy 3D time-of-ﬂight (3D-ToF) camera that has been coupled with a high-resolution RGB camera. Our framework is inspired by recent work that uses nonlocal means ﬁltering to regularize depth maps in order to maintain ﬁne detail and structure. Our framework extends this regularization with an additional edge weighting scheme based on several image features based on the additional high-resolution RGB input. Quantitative and qualitative results show that our method outperforms existing approaches for 3D-ToF upsampling. We describe the complete process for this system, including device calibration, scene warping for input alignment, and even how the results can be further processed using simple user markup.},
	language = {en},
	urldate = {2018-11-25},
	booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
	publisher = {IEEE},
	author = {Park, Jaesik and Kim, Hyeongwoo and {Yu-Wing Tai} and Brown, Michael S. and Kweon, Inso},
	month = nov,
	year = {2011},
	pages = {1623--1630},
	file = {Park et al. - 2011 - High quality depth map upsampling for 3D-TOF camer.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/U8657FHK/Park et al. - 2011 - High quality depth map upsampling for 3D-TOF camer.pdf:application/pdf}
}

@inproceedings{ferstl_image_2013,
	address = {Sydney, Australia},
	title = {Image {Guided} {Depth} {Upsampling} {Using} {Anisotropic} {Total} {Generalized} {Variation}},
	isbn = {978-1-4799-2840-8},
	url = {http://ieeexplore.ieee.org/document/6751233/},
	doi = {10.1109/ICCV.2013.127},
	abstract = {In this work we present a novel method for the challenging problem of depth image upsampling. Modern depth cameras such as Kinect or Time of Flight cameras deliver dense, high quality depth measurements but are limited in their lateral resolution. To overcome this limitation we formulate a convex optimization problem using higher order regularization for depth image upsampling. In this optimization an anisotropic diffusion tensor, calculated from a high resolution intensity image, is used to guide the upsampling. We derive a numerical algorithm based on a primaldual formulation that is efﬁciently parallelized and runs at multiple frames per second. We show that this novel upsampling clearly outperforms state of the art approaches in terms of speed and accuracy on the widely used Middlebury 2007 datasets. Furthermore, we introduce novel datasets with highly accurate groundtruth, which, for the ﬁrst time, enable to benchmark depth upsampling methods using real sensor data.},
	language = {en},
	urldate = {2018-11-25},
	booktitle = {2013 {IEEE} {International} {Conference} on {Computer} {Vision}},
	publisher = {IEEE},
	author = {Ferstl, David and Reinbacher, Christian and Ranftl, Rene and Ruether, Matthias and Bischof, Horst},
	month = dec,
	year = {2013},
	pages = {993--1000},
	file = {Ferstl et al. - 2013 - Image Guided Depth Upsampling Using Anisotropic To.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/IV9VKP8U/Ferstl et al. - 2013 - Image Guided Depth Upsampling Using Anisotropic To.pdf:application/pdf}
}

@article{zbontar_computing_2015,
	title = {Computing the {Stereo} {Matching} {Cost} with a {Convolutional} {Neural} {Network}},
	url = {http://arxiv.org/abs/1409.4326},
	doi = {10.1109/CVPR.2015.7298767},
	abstract = {We present a method for extracting depth information from a rectified image pair. We train a convolutional neural network to predict how well two image patches match and use it to compute the stereo matching cost. The cost is refined by cross-based cost aggregation and semiglobal matching, followed by a left-right consistency check to eliminate errors in the occluded regions. Our stereo method achieves an error rate of 2.61 \% on the KITTI stereo dataset and is currently (August 2014) the top performing method on this dataset.},
	urldate = {2018-11-25},
	journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	author = {Žbontar, Jure and LeCun, Yann},
	month = jun,
	year = {2015},
	note = {arXiv: 1409.4326},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	pages = {1592--1599},
	annote = {Comment: Conference on Computer Vision and Pattern Recognition (CVPR), June 2015},
	file = {arXiv\:1409.4326 PDF:/Users/guillaume/Documents/Scolaire/Zotero/storage/AMWMP47Y/Žbontar and LeCun - 2015 - Computing the Stereo Matching Cost with a Convolut.pdf:application/pdf;arXiv.org Snapshot:/Users/guillaume/Documents/Scolaire/Zotero/storage/N4MS9Z8D/1409.html:text/html}
}

@incollection{jiang_high-resolution_2014,
	address = {Cham},
	title = {High-{Resolution} {Stereo} {Datasets} with {Subpixel}-{Accurate} {Ground} {Truth}},
	volume = {8753},
	isbn = {978-3-319-11751-5 978-3-319-11752-2},
	url = {http://link.springer.com/10.1007/978-3-319-11752-2_3},
	abstract = {We present a structured lighting system for creating highresolution stereo datasets of static indoor scenes with highly accurate ground-truth disparities. The system includes novel techniques for eﬃcient 2D subpixel correspondence search and self-calibration of cameras and projectors with modeling of lens distortion. Combining disparity estimates from multiple projector positions we are able to achieve a disparity accuracy of 0.2 pixels on most observed surfaces, including in halfoccluded regions. We contribute 33 new 6-megapixel datasets obtained with our system and demonstrate that they present new challenges for the next generation of stereo algorithms.},
	language = {en},
	urldate = {2018-12-30},
	booktitle = {Pattern {Recognition}},
	publisher = {Springer International Publishing},
	author = {Scharstein, Daniel and Hirschmüller, Heiko and Kitajima, York and Krathwohl, Greg and Nešić, Nera and Wang, Xi and Westling, Porter},
	editor = {Jiang, Xiaoyi and Hornegger, Joachim and Koch, Reinhard},
	year = {2014},
	doi = {10.1007/978-3-319-11752-2_3},
	pages = {31--42},
	file = {Scharstein et al. - 2014 - High-Resolution Stereo Datasets with Subpixel-Accu.pdf:/Users/guillaume/Documents/Scolaire/Zotero/storage/6RJ4LEAR/Scharstein et al. - 2014 - High-Resolution Stereo Datasets with Subpixel-Accu.pdf:application/pdf}
}